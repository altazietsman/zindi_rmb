{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotnine as pn\n",
    "from plotnine import aes, ggplot\n",
    "import pathlib\n",
    "from datetime import datetime\n",
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Datasets\n",
    "The following datasets are used:\n",
    "- cpi file as supplied by zindi\n",
    "- currency as supplied by zindi\n",
    "- jse data as supplied by zindi\n",
    "-  Monthly credit detail excel released by the reserve bank (https://www.resbank.co.za/en/home/what-we-do/statistics/releases/selected-statistics)\n",
    "- Money and banking detail excel released by the reserve bank (https://www.resbank.co.za/en/home/what-we-do/statistics/releases/selected-statistics)\n",
    "- fuel prices pulled from open price engin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get directory path\n",
    "path = str(pathlib.Path().cwd().parent.parent.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi_raw = pd.read_excel(path + '/data/EXCEL - CPI(5 and 8 digit) from Jan 2017 (202306).xlsx', dtype=\"object\")\n",
    "currency = pd.read_csv(path + '/data/currency_data.csv')\n",
    "credit = pd.read_excel(path + '/data/credit.xlsx', header=1)\n",
    "jse = pd.read_csv(path + '/data/jse_indices.csv')\n",
    "fuel = pd.read_csv(path + '/data/fuel_df.csv').drop(['Unnamed: 0'], axis=1)\n",
    "sabor = pd.read_csv(path + '/data/sabor.csv')\n",
    "money = pd.read_excel(path + '/data/money.xlsx', header=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 12 main categories that are used to calculate the Headline CPI. Each category has a number of sub categories. This data set contains the CPI on sub-category level.\n",
    "\n",
    "Create a dataset where the CPI is calculated on the category level. These values will then be used in the models to predict the CPI for the different categories as well as the Headline CPI.\n",
    "\n",
    "In terms of cleaning the data, I will do the following:\n",
    "- Remove unnecessary columns.\n",
    "- Change column headers to make them more explanatory.\n",
    "- Replace all `..` entries with a `0`. There are products which were included in the CPI calculations at a later stage and some products that were removed from the CPI calculation. Categories with no value at the time has a `..`, I will replace them with a `0`. The type of the column can then be updated to float.\n",
    "- Combine the `Super maize` and `Special maize` categories into a single `Maize meal` category, to correspond with the current use of maize meal.\n",
    "- Create a function to calculate the CPI values for each month using the weights provided in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_montly_cpi(raw_df):\n",
    "    \"\"\"Function that takes the raw cpi data for each product from statssa and calculates the cpi value per category\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "    raw_df: pandas dataframe\n",
    "            dataframe containing raw data from statsa\n",
    "\n",
    "    Return:\n",
    "    -------\n",
    "    df_cpi: pandas dataframe\n",
    "            dataframe containing the monthly cpi per category\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. remove unecessary columns and rename\n",
    "    list_cols_to_drop = [\"H01\", \"H02\", \"H05\", \"H06\", \"H07\"]\n",
    "    cat_cpi_df = raw_df.copy().drop(list_cols_to_drop, axis=1).copy()\n",
    "\n",
    "    cat_cpi_df.rename(\n",
    "        columns={\n",
    "            \"H03\": \"category_codes\",\n",
    "            \"H04\": \"category_descr\",\n",
    "            \"Weight (All urban)\": \"weights_urban\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    # 2. replace .. with zeros\n",
    "    cat_cpi_df.replace(\"..\", 0, inplace=True)\n",
    "\n",
    "    # 3. combine maize meal categories\n",
    "    cat_cpi_df.iloc[17:19] = (\n",
    "        cat_cpi_df.iloc[17:19].copy().apply(pd.to_numeric, errors=\"coerce\")\n",
    "    )\n",
    "    divided_row = (cat_cpi_df.iloc[17].copy() + cat_cpi_df.iloc[18].copy()) / 2\n",
    "    cat_cpi_df.iloc[15] = [\n",
    "        divided_row[i] if value == 0 else value\n",
    "        for i, value in enumerate(cat_cpi_df.iloc[15].copy())\n",
    "    ]\n",
    "    cat_cpi_df.drop([cat_cpi_df.index[17], cat_cpi_df.index[18]], inplace=True)\n",
    "\n",
    "    # Convert the 'weights_urban' column to float\n",
    "    cat_cpi_df[\"weights_urban\"] = cat_cpi_df[\"weights_urban\"].astype(\"float\")\n",
    "\n",
    "    # 4. calculate cpi\n",
    "    # Assign a main category code to each raw data row.\n",
    "    main_category = []\n",
    "    for index, row in cat_cpi_df.iterrows():\n",
    "        if (len(row[\"category_codes\"]) == 8) & (\n",
    "            row[\"category_codes\"][:2] in [\"01\", \"02\"]\n",
    "        ):\n",
    "            main_category.append(row[\"category_codes\"][:2])\n",
    "        elif (\n",
    "            len(row[\"category_codes\"]) == 5\n",
    "        ):  # & (row['category_codes'][:2] not in [\"04\",\"07\"]):\n",
    "            main_category.append(row[\"category_codes\"][:2])\n",
    "        else:\n",
    "            main_category.append(\"no\")\n",
    "\n",
    "    cat_cpi_df[\"main_category_code\"] = main_category\n",
    "\n",
    "    # Drop the rows where the main_category_code is \"no\". That is to prevent double counting.\n",
    "    # Some categories have a sub category included in the data.\n",
    "    cat_cpi_df.drop(\n",
    "        cat_cpi_df[cat_cpi_df[\"main_category_code\"] == \"no\"].index, inplace=True\n",
    "    )\n",
    "\n",
    "    # Sum the weights for each category\n",
    "    sum_weights = cat_cpi_df.groupby(\"main_category_code\")[\"weights_urban\"].sum()\n",
    "\n",
    "    # create new cpi dataframe\n",
    "    cpi_df = pd.DataFrame()\n",
    "\n",
    "    # For each month create the headline CPI value and the CPI value per category.\n",
    "    for col in range(3, cat_cpi_df.shape[1] - 1):\n",
    "        cat_cpi_df = cat_cpi_df.copy()\n",
    "        column_name = cat_cpi_df.columns[col]\n",
    "        cat_cpi_df[\"weighted_index_\" + column_name] = (\n",
    "            cat_cpi_df[\"weights_urban\"] * cat_cpi_df[column_name]\n",
    "        )\n",
    "\n",
    "        sum_weighted_index = cat_cpi_df.groupby(\"main_category_code\")[\n",
    "            \"weighted_index_\" + column_name\n",
    "        ].sum()\n",
    "\n",
    "        # Concatenate the DataFrames horizontally\n",
    "        concat_df = pd.concat([sum_weights, sum_weighted_index], axis=1)\n",
    "\n",
    "        # Add a row that sums the values in the columns\n",
    "        sums_df = pd.DataFrame(\n",
    "            concat_df.sum().values.reshape(1, -1), columns=concat_df.columns\n",
    "        )\n",
    "        sums_df = sums_df.set_index(pd.Index([\"headline\"]))\n",
    "\n",
    "        # Concatenate the headline dataframe to the categories\n",
    "        month_cpi_df = pd.concat([concat_df, sums_df], axis=0)\n",
    "\n",
    "        # Calculate the CPI value\n",
    "        month_cpi_df[\"cpi_\" + column_name] = (\n",
    "            month_cpi_df[\"weighted_index_\" + column_name]\n",
    "            / month_cpi_df[\"weights_urban\"]\n",
    "        ).round(1)\n",
    "\n",
    "        cpi_df = pd.concat(\n",
    "            [cpi_df, month_cpi_df[[\"weights_urban\", \"cpi_\" + column_name]]], axis=1\n",
    "        )\n",
    "\n",
    "    # Remove duplicate weights columns and reset the index\n",
    "    cpi_df = cpi_df.loc[:, ~cpi_df.columns.duplicated()]\n",
    "    cpi_df = cpi_df.reset_index().rename(columns={\"index\": \"category\"})\n",
    "\n",
    "    # Dataframe with just the CPI values:\n",
    "    cpi_df = cpi_df.drop(\"weights_urban\", axis=1).copy()\n",
    "    transposed_cpi_df = cpi_df.set_index(\"category\").transpose().reset_index()\n",
    "    transposed_cpi_df[\"date\"] = transposed_cpi_df[\"index\"].apply(\n",
    "        lambda x: x.split(\"M\")[-1]\n",
    "    )\n",
    "    transposed_cpi_df[\"date\"] = transposed_cpi_df[\"date\"].apply(\n",
    "        lambda x: x[:4] + \"-\" + x[-2:]\n",
    "    )\n",
    "    # change month to datetime format\n",
    "    transposed_cpi_df[\"date\"] = pd.to_datetime(transposed_cpi_df[\"date\"]).dt.strftime(\n",
    "        \"%Y-%m\"\n",
    "    )\n",
    "\n",
    "    return transposed_cpi_df.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi = get_montly_cpi(raw_df=cpi_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a category dictionary with the category code and description\n",
    "category_dict = {\n",
    "    \"01\": \"Food and non-alcoholic beverages\",\n",
    "    \"02\": \"Alcoholic beverages and tobacco\",\n",
    "    \"03\": \"Clothing and footwear\",\n",
    "    \"04\": \"Housing and utilities\",\n",
    "    \"05\": \"Household contents and services\",\n",
    "    \"06\": \"Health\",\n",
    "    \"07\": \"Transport\",\n",
    "    \"08\": \"Communication\",\n",
    "    \"09\": \"Recreation and culture\",\n",
    "    \"10\": \"Education\",\n",
    "    \"11\": \"Restaurants and hotels\",\n",
    "    \"12\": \"Miscellaneous goods and services\",\n",
    "    \"headline\": \"headline CPI\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi.rename(columns = category_dict, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change dates to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change month to datetime format\n",
    "cpi['Date'] = pd.to_datetime(cpi['date']).dt.strftime('%Y-%m')\n",
    "currency['Date'] = pd.to_datetime(currency['Date']).dt.strftime('%Y-%m')\n",
    "jse['Date'] = pd.to_datetime(jse['date']).dt.strftime('%Y-%m')\n",
    "credit['date'] = pd.to_datetime(credit['Date'], format='%b, %Y')\n",
    "credit['Date'] = pd.to_datetime(credit['date']).dt.strftime('%Y-%m')\n",
    "money['date'] = pd.to_datetime(money['Date'], format='%b, %Y')\n",
    "money['Date'] = pd.to_datetime(money['date']).dt.strftime('%Y-%m')\n",
    "fuel['Date'] = pd.to_datetime(fuel['date']).dt.strftime('%Y-%m')\n",
    "sabor['Date'] = pd.to_datetime(sabor['date']).dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only select dates from 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change month to datetime format\n",
    "cpi_new = cpi[cpi['Date'] > '2018']\n",
    "currency_new = currency[currency['Date'] > '2018']\n",
    "jse_new = jse[jse['Date'] > '2018']\n",
    "credit_new= credit[credit['Date'] > '2018']\n",
    "money_new= money[money['Date'] > '2018']\n",
    "fuel_new= fuel[fuel['Date'] > '2018']\n",
    "sabor_new= sabor[sabor['Date'] > '2018']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the credit and national excels the commas in values need to be stripped and values turned in to intergers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_commas_and_convert_to_float(value):\n",
    "    return float(value.replace(',', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_new = credit_new.drop(['Share of corporations as a % of total credit',\n",
    "       'Share of corporations as a % of total loans & advances',\n",
    "       'Share of households as a % of total credit',\n",
    "       'Share of households as % of total loans & advances', 'Investments'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_columns = ['Instalment sale credit', 'Leasing finance',\n",
    "       'Mortgage advances', 'Overdrafts', 'General loans and advances',\n",
    "       'Credit card advances', 'Of which: Total to households',\n",
    "       'Total loans and advances : Households',\n",
    "       'Claims on the domestic private sector',\n",
    "       'Total loans and advances (excl. investments & bills)',\n",
    "       'Bills discounted', 'Instalment sale credit.1', 'Leasing finance.1',\n",
    "       'Mortgage advances.1', 'Overdrafts.1', 'General loans and advances.1',\n",
    "       'Credit card advances.1', 'Of which: Total to corporations',\n",
    "       'Claims on the domestic private sector.1',\n",
    "       'Total loans and advances : Corporations',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_new[credit_columns] = credit_new[credit_columns].applymap(remove_commas_and_convert_to_float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "money_columns = ['M0', 'M1A', 'M1', 'M2', 'Total monetary (M3) deposits',\n",
    "       'M3 Seasonally adjusted',\n",
    "       'Net foreign assets', 'Net claims on Government sector:',\n",
    "       '-> Gross claims', '-> Government deposits',\n",
    "       'Claims on the private sector', 'Net other assets', 'Change in M3',\n",
    "       'Claims on the domestic private sector (seasonally adjusted)',\n",
    "       'Claims on the domestic private sector', 'Investments',\n",
    "       'Bills discounted',\n",
    "       'Total loans and advances (excl. investments & bills)',\n",
    "       '---> Instalment sales credit', '---> Leasing finance',\n",
    "       '---> Mortgage advances', '---> Other loans and advances',\n",
    "       'Of which: Total to households', 'Net claims on the government sector',\n",
    "       'Total domestic credit extension']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gx/c35dzbl95sg3t62y03g1j6s40000gn/T/ipykernel_66403/1254540229.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "money_new[money_columns] = money_new[money_columns].applymap(remove_commas_and_convert_to_float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Features\n",
    "\n",
    "In some of the excel sheets we do not have up to date. We will there use the feature from 2 months ao as the feature for now (ie march is the predictor for July)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01\n",
      "2018-01\n",
      "2018-01\n",
      "2018-01\n",
      "2018-01\n",
      "2018-01\n",
      "2018-01\n"
     ]
    }
   ],
   "source": [
    "print(jse_new['Date'].min())\n",
    "print(credit_new['Date'].min())\n",
    "print(currency_new['Date'].min())\n",
    "print(cpi_new['Date'].min())\n",
    "print(fuel_new['Date'].min())\n",
    "print(sabor_new['Date'].min())\n",
    "print(money_new['Date'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06\n",
      "2023-06\n",
      "2023-06\n",
      "2023-06\n",
      "2023-07\n",
      "2023-06\n",
      "2023-06\n"
     ]
    }
   ],
   "source": [
    "print(jse_new['Date'].max())\n",
    "print(credit_new['Date'].max())\n",
    "print(currency_new['Date'].max())\n",
    "print(cpi_new['Date'].max())\n",
    "print(fuel_new['Date'].max())\n",
    "print(sabor_new['Date'].max())\n",
    "print(money_new['Date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gx/c35dzbl95sg3t62y03g1j6s40000gn/T/ipykernel_66403/1031231211.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/var/folders/gx/c35dzbl95sg3t62y03g1j6s40000gn/T/ipykernel_66403/1031231211.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/var/folders/gx/c35dzbl95sg3t62y03g1j6s40000gn/T/ipykernel_66403/1031231211.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "jse_new['newDate'] = (pd.to_datetime(jse_new['Date']) + pd.DateOffset(months=2)).dt.strftime('%Y-%m')\n",
    "credit_new['newDate'] = (pd.to_datetime(credit_new['Date']) + pd.DateOffset(months=2)).dt.strftime('%Y-%m')\n",
    "currency_new['newDate'] = (pd.to_datetime(currency_new['Date']) + pd.DateOffset(months=2)).dt.strftime('%Y-%m')\n",
    "fuel_new['newDate'] = (pd.to_datetime(fuel_new['Date']) + pd.DateOffset(months=2)).dt.strftime('%Y-%m')\n",
    "sabor_new['newDate'] = (pd.to_datetime(sabor_new['Date']) + pd.DateOffset(months=2)).dt.strftime('%Y-%m')\n",
    "money_new['newDate'] = (pd.to_datetime(money_new['Date']) + pd.DateOffset(months=2)).dt.strftime('%Y-%m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "jse_new = jse_new.drop(['Date', 'date'], axis=1)\n",
    "credit_new = credit_new.drop(['Date', 'date'], axis=1)\n",
    "currency_new = currency_new.drop(['Date'], axis=1)\n",
    "fuel_new = fuel_new.drop(['Date', 'date'], axis=1)\n",
    "sabor_new = sabor_new.drop(['Date', 'date'], axis=1)\n",
    "money_new = money_new.drop(['Date', 'date'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get mean per Month for jse and currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_mean = credit_new.groupby(['newDate']).mean().reset_index().add_suffix(\"mean\")\n",
    "jse_mean = jse_new.groupby(['newDate']).mean().reset_index().add_suffix(\"mean\")\n",
    "currency_mean = currency_new.groupby(['newDate']).mean().reset_index().add_suffix(\"mean\")\n",
    "fuel_new = fuel_new.groupby(['newDate']).mean().reset_index()\n",
    "sabor_new = sabor_new.groupby(['newDate']).mean().reset_index()\n",
    "money_mean = money_new.groupby(['newDate']).mean().reset_index().add_suffix(\"mean\")\n",
    "\n",
    "credit_std = credit_new.groupby(['newDate']).std().reset_index().add_suffix(\"std\")\n",
    "jse_std = jse_new.groupby(['newDate']).std().reset_index().add_suffix(\"std\")\n",
    "currency_std = currency_new.groupby(['newDate']).std().reset_index().add_suffix(\"std\")\n",
    "money_std = money_new.groupby(['newDate']).std().reset_index().add_suffix(\"std\")\n",
    "\n",
    "credit_min = credit_new.groupby(['newDate']).min().reset_index().add_suffix(\"min\")\n",
    "jse_min = jse_new.groupby(['newDate']).min().reset_index().add_suffix(\"min\")\n",
    "currency_min = currency_new.groupby(['newDate']).min().reset_index().add_suffix(\"min\")\n",
    "money_min = money_new.groupby(['newDate']).min().reset_index().add_suffix(\"min\")\n",
    "\n",
    "credit_max = credit_new.groupby(['newDate']).max().reset_index().add_suffix(\"max\")\n",
    "jse_max = jse_new.groupby(['newDate']).max().reset_index().add_suffix(\"max\")\n",
    "currency_max = currency_new.groupby(['newDate']).max().reset_index().add_suffix(\"max\")\n",
    "money_max = money_new.groupby(['newDate']).max().reset_index().add_suffix(\"max\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_new = credit_mean.merge(credit_std, left_on='newDatemean', right_on='newDatestd', how='left').drop(['newDatestd'], axis=1)\n",
    "credit_new = credit_new.merge(credit_max, left_on='newDatemean', right_on='newDatemax', how='left').drop(['newDatemax'], axis=1)\n",
    "credit_new = credit_new.merge(credit_min, left_on='newDatemean', right_on='newDatemin', how='left').drop(['newDatemin'], axis=1)\n",
    "credit_new = credit_new.rename(columns={\"newDatemean\": \"newDate\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "money_new = money_mean.merge(money_std, left_on='newDatemean', right_on='newDatestd', how='left').drop(['newDatestd'], axis=1)\n",
    "money_new = money_new.merge(money_max, left_on='newDatemean', right_on='newDatemax', how='left').drop(['newDatemax'], axis=1)\n",
    "money_new = money_new.merge(money_min, left_on='newDatemean', right_on='newDatemin', how='left').drop(['newDatemin'], axis=1)\n",
    "money_new = money_new.rename(columns={\"newDatemean\": \"newDate\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "jse_new = jse_mean.merge(jse_std, left_on='newDatemean', right_on='newDatestd', how='left').drop(['newDatestd'], axis=1)\n",
    "jse_new = jse_new.merge(jse_max, left_on='newDatemean', right_on='newDatemax', how='left').drop(['newDatemax'], axis=1)\n",
    "jse_new = jse_new.merge(jse_min, left_on='newDatemean', right_on='newDatemin', how='left').drop(['newDatemin'], axis=1)\n",
    "jse_new = jse_new.rename(columns={\"newDatemean\": \"newDate\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_new = currency_mean.merge(currency_std, left_on='newDatemean', right_on='newDatestd', how='left').drop(['newDatestd'], axis=1)\n",
    "currency_new = currency_new.merge(currency_max, left_on='newDatemean', right_on='newDatemax', how='left').drop(['newDatemax'], axis=1)\n",
    "currency_new = currency_new.merge(currency_min, left_on='newDatemean', right_on='newDatemin', how='left').drop(['newDatemin'], axis=1)\n",
    "currency_new = currency_new.rename(columns={\"newDatemean\": \"newDate\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge data together for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi_all = cpi_new.drop(['date'], axis=1).merge(jse_new, right_on='newDate', left_on='Date', how='left')\n",
    "cpi_all = cpi_all.drop(['newDate'], axis=1).merge(credit_new, right_on='newDate', left_on='Date', how='left')\n",
    "cpi_all = cpi_all.drop(['newDate'], axis=1).merge(currency_new, right_on='newDate', left_on='Date', how='left')\n",
    "cpi_all = cpi_all.drop(['newDate'], axis=1).merge(fuel_new, right_on='newDate', left_on='Date', how='left')\n",
    "cpi_all = cpi_all.drop(['newDate'], axis=1).merge(sabor_new, right_on='newDate', left_on='Date', how='left')\n",
    "cpi_all = cpi_all.drop(['newDate'], axis=1).merge(money_new, right_on='newDate', left_on='Date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi_all = cpi_all[cpi_all['Date'] > '2018-03']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "We will model one index at a time to see what works the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.models import HoltWintersWrapper, ProphetWrapper\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_model(cpi, month):\n",
    "\n",
    "    hw_cpi_cat = ['Health', 'Education']\n",
    "    cpi_cat = ['headline CPI',\n",
    "                'Food and non-alcoholic beverages',\n",
    "                'Alcoholic beverages and tobacco',\n",
    "                'Clothing and footwear',\n",
    "                'Housing and utilities',\n",
    "                'Household contents and services',\n",
    "                'Transport',\n",
    "                'Communication',\n",
    "                'Recreation and culture',\n",
    "                'Restaurants and hotels',\n",
    "                'Miscellaneous goods and services']\n",
    "\n",
    "    hw_6_results = []\n",
    "    prophet_multi = []\n",
    "\n",
    "    # fit hw\n",
    "    for cat in hw_cpi_cat:\n",
    "        # df = cpi_all[cpi_all['Category'] == cat]\n",
    "        df = cpi.copy()\n",
    "\n",
    "        hw_6 = HoltWintersWrapper(seasonal_periods=6)\n",
    "\n",
    "        hw_6.fit(y=df[df['Date'] < month].sort_values(by='Date')[cat].values)\n",
    "\n",
    "        hw_6_results.append(hw_6.predict(forcast=1)[0])\n",
    "\n",
    "    df_hw_results = pd.DataFrame({'cat':hw_cpi_cat, 'pred':hw_6_results})\n",
    "\n",
    "    df_features = sabor_new.merge(fuel_new, right_on='newDate', left_on='newDate', how='left')\n",
    "\n",
    "    for cat in cpi_cat:\n",
    "        # df = cpi_all[cpi_all['Category'] == cat]\n",
    "        df = cpi.copy()\n",
    "\n",
    "        # reorder and drop columns\n",
    "        df.insert(0, 'ds', df.pop('Date'))\n",
    "        df.insert(1, 'y', df.pop(cat))\n",
    "        df = df[['ds', 'y', 'sabor']]\n",
    "\n",
    "        # model\n",
    "        prophet = ProphetWrapper(n_changepoints=2, seasonality_mode=\"multiplicative\")\n",
    "        prophet.fit(df[df['ds'] < month].sort_values(by='ds').sort_values(by='ds'))\n",
    "\n",
    "        df_predict = pd.DataFrame({'ds': [month]})\n",
    "        df_predict['ds'] = pd.to_datetime(df_predict['ds']).dt.strftime('%Y-%m')\n",
    "\n",
    "        df_predict = df_predict.merge(df_features, left_on='ds', right_on='newDate').drop(['newDate'], axis=1)\n",
    "        df_predict_columns = df.drop(['y'], axis=1).columns\n",
    "        prophet_multi.append(prophet.predict(df_predict[df_predict_columns])[0])\n",
    "\n",
    "    df_prophet_results = pd.DataFrame({'cat':cpi_cat, 'pred':prophet_multi})\n",
    "\n",
    "    df_results = pd.concat([df_hw_results, df_prophet_results])\n",
    "\n",
    "    return df_results\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get April predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gx/c35dzbl95sg3t62y03g1j6s40000gn/T/ipykernel_66403/1247225683.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/var/folders/gx/c35dzbl95sg3t62y03g1j6s40000gn/T/ipykernel_66403/1247225683.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/var/folders/gx/c35dzbl95sg3t62y03g1j6s40000gn/T/ipykernel_66403/1247225683.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/var/folders/gx/c35dzbl95sg3t62y03g1j6s40000gn/T/ipykernel_66403/1247225683.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/var/folders/gx/c35dzbl95sg3t62y03g1j6s40000gn/T/ipykernel_66403/1247225683.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/var/folders/gx/c35dzbl95sg3t62y03g1j6s40000gn/T/ipykernel_66403/1247225683.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/var/folders/gx/c35dzbl95sg3t62y03g1j6s40000gn/T/ipykernel_66403/1247225683.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/var/folders/gx/c35dzbl95sg3t62y03g1j6s40000gn/T/ipykernel_66403/1247225683.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/var/folders/gx/c35dzbl95sg3t62y03g1j6s40000gn/T/ipykernel_66403/1247225683.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/var/folders/gx/c35dzbl95sg3t62y03g1j6s40000gn/T/ipykernel_66403/1247225683.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    }
   ],
   "source": [
    "df_results_apr = combined_model(cpi=cpi_all, month='2023-04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Health</td>\n",
       "      <td>109.248368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Education</td>\n",
       "      <td>110.400057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>headline CPI</td>\n",
       "      <td>110.223440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Food and non-alcoholic beverages</td>\n",
       "      <td>118.787710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alcoholic beverages and tobacco</td>\n",
       "      <td>110.328788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clothing and footwear</td>\n",
       "      <td>103.828139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Housing and utilities</td>\n",
       "      <td>104.646256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Household contents and services</td>\n",
       "      <td>108.242326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Transport</td>\n",
       "      <td>120.258265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Communication</td>\n",
       "      <td>99.627989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Recreation and culture</td>\n",
       "      <td>104.972996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Restaurants and hotels</td>\n",
       "      <td>110.782769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Miscellaneous goods and services</td>\n",
       "      <td>108.637109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 cat        pred\n",
       "0                             Health  109.248368\n",
       "1                          Education  110.400057\n",
       "0                       headline CPI  110.223440\n",
       "1   Food and non-alcoholic beverages  118.787710\n",
       "2    Alcoholic beverages and tobacco  110.328788\n",
       "3              Clothing and footwear  103.828139\n",
       "4              Housing and utilities  104.646256\n",
       "5    Household contents and services  108.242326\n",
       "6                          Transport  120.258265\n",
       "7                      Communication   99.627989\n",
       "8             Recreation and culture  104.972996\n",
       "9             Restaurants and hotels  110.782769\n",
       "10  Miscellaneous goods and services  108.637109"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_apr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi_apr = cpi_all[cpi_all['Date'] == '2023-04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi_apr = cpi_apr[list(category_dict.values())].transpose().reset_index()\n",
    "cpi_apr.columns = ['Category', 'Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_apr = df_results_apr.merge(cpi_apr[['Category', 'Value']], left_on='cat', right_on='Category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apr RMSE prophet multi:  2.138942006530779\n"
     ]
    }
   ],
   "source": [
    "rmse_apr = mean_squared_error(df_results_apr['pred'], df_results_apr['Value'], squared=False)\n",
    "print('Apr RMSE prophet multi: ', rmse_apr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_apr = df_results_apr[['cat', 'pred']]\n",
    "df_results_apr.columns = ['ID', 'Value']\n",
    "\n",
    "month = \"April\"\n",
    "\n",
    "pred_map = {'Headline_CPI': f'{month}_headline CPI',\n",
    "'Alcoholic beverages and tobacco': f'{month}_alcoholic beverages and tobacco',\n",
    "'Clothing and footwear': f'{month}_clothing and footwear',\n",
    "'Communication': f'{month}_communication',\n",
    "'Education': f'{month}_education',\n",
    "'Food and non-alcoholic beverages': f'{month}_food and non-alcoholic beverages',\n",
    "'Health': f'{month}_health',\n",
    "'Household contents and services': f'{month}_household contents and services',\n",
    "'Housing and utilities': f'{month}_housing and utilities',\n",
    "'Miscellaneous goods and services': f'{month}_miscellaneous goods and services',\n",
    "'Recreation and culture': f'{month}_recreation and culture',\n",
    "'Restaurants and hotels ': f'{month}_restaurants and hotels',\n",
    "'Transport': f'{month}_transport'}\n",
    "\n",
    "df_results_apr = df_results_apr.replace(pred_map)\n",
    "\n",
    "df_results_apr.to_csv(path + '/submissions/apr_testing.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get May predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_may = combined_model(cpi_all=cpi_all, month='2023-05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi_may = cpi_all[cpi_all['Date'] == '2023-05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_may = df_results_may.merge(cpi_may[['Category', 'Value']], left_on='cat', right_on='Category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_may = mean_squared_error(df_results_may['pred'], df_results_may['Value'], squared=False)\n",
    "print('May RMSE prophet multo: ', rmse_may)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_may = df_results_may[['cat', 'pred']]\n",
    "df_results_may.columns = ['ID', 'Value']\n",
    "\n",
    "month = \"May\"\n",
    "\n",
    "pred_map = {'Headline_CPI': f'{month}_headline CPI',\n",
    "'Alcoholic beverages and tobacco': f'{month}_alcoholic beverages and tobacco',\n",
    "'Clothing and footwear': f'{month}_clothing and footwear',\n",
    "'Communication': f'{month}_communication',\n",
    "'Education': f'{month}_education',\n",
    "'Food and non-alcoholic beverages': f'{month}_food and non-alcoholic beverages',\n",
    "'Health': f'{month}_health',\n",
    "'Household contents and services': f'{month}_household contents and services',\n",
    "'Housing and utilities': f'{month}_housing and utilities',\n",
    "'Miscellaneous goods and services': f'{month}_miscellaneous goods and services',\n",
    "'Recreation and culture': f'{month}_recreation and culture',\n",
    "'Restaurants and hotels ': f'{month}_restaurants and hotels',\n",
    "'Transport': f'{month}_transport'}\n",
    "\n",
    "df_results_may = df_results_may.replace(pred_map)\n",
    "\n",
    "df_results_may.to_csv(path + '/submissions/may_testing.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get June predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_june = combined_model(cpi_all=cpi_all, month='2023-06')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_june['Value'] = [110.8, 110.4, 109.8, 118.3, 110.9, 104.3, 105.4, 107.7, 112.3, 99.6, 105.3, 110.0, 109.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_June = mean_squared_error(df_results_june['pred'], df_results_june['Value'], squared=False)\n",
    "print('June RMSE prophet multo: ', rmse_June)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_june = df_results_june[['cat', 'pred']]\n",
    "df_results_june.columns = ['ID', 'Value']\n",
    "\n",
    "month = \"June\"\n",
    "\n",
    "pred_map = {'Headline_CPI': f'{month}_headline CPI',\n",
    "'Alcoholic beverages and tobacco': f'{month}_alcoholic beverages and tobacco',\n",
    "'Clothing and footwear': f'{month}_clothing and footwear',\n",
    "'Communication': f'{month}_communication',\n",
    "'Education': f'{month}_education',\n",
    "'Food and non-alcoholic beverages': f'{month}_food and non-alcoholic beverages',\n",
    "'Health': f'{month}_health',\n",
    "'Household contents and services': f'{month}_household contents and services',\n",
    "'Housing and utilities': f'{month}_housing and utilities',\n",
    "'Miscellaneous goods and services': f'{month}_miscellaneous goods and services',\n",
    "'Recreation and culture': f'{month}_recreation and culture',\n",
    "'Restaurants and hotels ': f'{month}_restaurants and hotels',\n",
    "'Transport': f'{month}_transport'}\n",
    "\n",
    "df_results_june = df_results_june.replace(pred_map)\n",
    "\n",
    "df_results_june.to_csv(path + '/submissions/june_testing.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get predictions for July"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_july = combined_model(cpi_all=cpi_all, month='2023-07')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_july.columns = ['ID', 'Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = 'July'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_map = {'Headline_CPI': f'{month}_headline CPI',\n",
    "'Alcoholic beverages and tobacco': f'{month}_alcoholic beverages and tobacco',\n",
    "'Clothing and footwear': f'{month}_clothing and footwear',\n",
    "'Communication': f'{month}_communication',\n",
    "'Education': f'{month}_education',\n",
    "'Food and non-alcoholic beverages': f'{month}_food and non-alcoholic beverages',\n",
    "'Health': f'{month}_health',\n",
    "'Household contents and services': f'{month}_household contents and services',\n",
    "'Housing and utilities': f'{month}_housing and utilities',\n",
    "'Miscellaneous goods and services': f'{month}_miscellaneous goods and services',\n",
    "'Recreation and culture': f'{month}_recreation and culture',\n",
    "'Restaurants and hotels ': f'{month}_restaurants and hotels',\n",
    "'Transport': f'{month}_transport'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_july = df_results_july.replace(pred_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_july.to_csv(path + '/submissions/2023-08-13_multi_july.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get August submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_aug = combined_model(cpi_all=cpi_all, month='2023-08')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_aug.columns = ['ID', 'Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = 'August'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_map = {'Headline_CPI': f'{month}_headline CPI',\n",
    "'Alcoholic beverages and tobacco': f'{month}_alcoholic beverages and tobacco',\n",
    "'Clothing and footwear': f'{month}_clothing and footwear',\n",
    "'Communication': f'{month}_communication',\n",
    "'Education': f'{month}_education',\n",
    "'Food and non-alcoholic beverages': f'{month}_food and non-alcoholic beverages',\n",
    "'Health': f'{month}_health',\n",
    "'Household contents and services': f'{month}_household contents and services',\n",
    "'Housing and utilities': f'{month}_housing and utilities',\n",
    "'Miscellaneous goods and services': f'{month}_miscellaneous goods and services',\n",
    "'Recreation and culture': f'{month}_recreation and culture',\n",
    "'Restaurants and hotels ': f'{month}_restaurants and hotels',\n",
    "'Transport': f'{month}_transport'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_aug = df_results_aug.replace(pred_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_aug.to_csv(path + '/submissions/2023-08-13_multi_aug.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('zindi_rmb')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c64d72df593dea6c761f2df73983bedc3ab4ce00cdb01364b040ea0205292cb4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
